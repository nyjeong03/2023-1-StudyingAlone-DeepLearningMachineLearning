#데이터를 바탕으로 도미,빙어를 구분하는 머신러닝

#KNeighborsClassifier : 사이킷런 패키지에서 k-최근접 이웃 알고리즘을 구현한 클래스 (가까운 참고 데이터의 기본값은 5)
from sklearn.neighbors import KNeighborsClassifier

bream_length = [25.4, 26.3, 26.5, 29.0, 29.0, 29.7, 29.7, 30.0, 30.0, 30.7, 31.0, 31.0, 
                31.5, 32.0, 32.0, 32.0, 33.0, 33.0, 33.5, 33.5, 34.0, 34.0, 34.5, 35.0, 
                35.0, 35.0, 35.0, 36.0, 36.0, 37.0, 38.5, 38.5, 39.5, 41.0, 41.0]
bream_weight = [242.0, 290.0, 340.0, 363.0, 430.0, 450.0, 500.0, 390.0, 450.0, 500.0, 475.0, 500.0, 
                500.0, 340.0, 600.0, 600.0, 700.0, 700.0, 610.0, 650.0, 575.0, 685.0, 620.0, 680.0, 
                700.0, 725.0, 720.0, 714.0, 850.0, 1000.0, 920.0, 955.0, 925.0, 975.0, 950.0]

smelt_length = [9.8, 10.5, 10.6, 11.0, 11.2, 11.3, 11.8, 11.8, 12.0, 12.2, 12.4, 13.0, 14.3, 15.0]
smelt_weight = [6.7, 7.5, 7.0, 9.7, 9.8, 8.7, 10.0, 9.9, 9.8, 12.2, 13.4, 12.2, 19.7, 19.9]

# 두리스트를 하나로 합침
length=bream_length + smelt_length 
weight=bream_weight + smelt_weight

#zip 함수 : 나열된 리스트에서 원소를 하나씩 꺼내줌
fish_data = [[l, w] for l, w, in zip(length, weight)] #(길이, 무게 쌍을 가진 리스트 생성

#정답 리스트 만들기
#길이와 무게 리스트에서 앞에 35개는 도미, 그다음 14개는 빙어
#도미는 1, 빙어는 0
fish_target = [1]*35+[0]*14

kn = KNeighborsClassifier()

#kn에 fish_data와 fish_target을 전달하여 도미를 찾기 위한 기준 학습
#fit() : 주어진 데이터로 알고리즘을 훈련시킨 뒤 훈련
kn.fit(fish_data, fish_target) 
#score 함수 : 사이킷런에서 모델을 평가하는 메서드
kn.score(fish_data, fish_target)

#결과 : 1.0이 나옴 => fish_data의 모든 답을 정확히 맞춤(정확도 100)

#predict() : 새로운 데이터의 정답 예측
kn.predict([[30,600]]) #리스트의 리스트 전달
#결과 : array([1])이 나옴 => 도미에 근접

#가까운 참고 데이터 기본값 변경
kn49 = KNeighborsClassifier(n_neighbors=49) #참고 데이터를 49개로 한 kn49 모델

kn49.fit(fish_data, fish_target)
kn49.score(fish_data ,fish_target)
#결과 : 0.7142857142857143 나옴 => 49개 중에 도미가 35개로 다수를 차지하므로 어떤 데이터를 넣어도 도미로 예측. 도미만 올바르게 맞히므로 정확도가 100보다 작음
